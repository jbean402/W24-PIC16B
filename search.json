[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Justine Constantino",
    "section": "",
    "text": "This is Justine Constantino’s Quarto blog for the PIC16B Winter quarter!\n☆:.｡.o(≧▽≦)o.｡.:☆"
  },
  {
    "objectID": "posts/HW 1 /index.html#create-a-database",
    "href": "posts/HW 1 /index.html#create-a-database",
    "title": "HW 1: Climate Data Visualization",
    "section": "1. Create a Database",
    "text": "1. Create a Database\nUsing the instructions from the homework, I first created a database with three tables: temperatures, stations, and countries.\nTo create a database from the NOAA climate data, I used sqlite3 to create the database and to query the data, as well as pandas to manipulate the dataframes.\n# importing the libraries  \nimport sqlite3 \nimport pandas as pd\nimport numpy as np \n\n# Importing the csv file \ntemps_df = pd.read_csv(\"temps.csv\")\ntemps_df.head()\nNext, the temperature database had to be cleaned. The prepare_df reorganizes the tempperature data so that it can be easily used.\ndef prepare_df(df):\n    df = df.set_index(keys=[\"ID\", \"Year\"])\n    df = df.stack()\n    df = df.reset_index()\n    df = df.rename(columns = {\"level_2\"  : \"Month\" , 0 : \"Temp\"})\n    df[\"Month\"] = df[\"Month\"].str[5:].astype(int)\n    df[\"Temp\"]  = df[\"Temp\"] / 100\n    return(df)\nNow, we are going to start creating the connection into the climate database. As per the homework, our database will be called climate-database.db.\nconn = sqlite3.connect(\"climate-database.db\") # temperature database\n\n\n\n\n\n\nNote\n\n\n\nWe realize that the temerature data set contains many rows, so it is better to have the data be loaded into the database in chunks. The following loop iterates through the 100000 rows of the data at a time, cleaning it with prepare_df and adding it to the database.\n\n\ntemps_iter = pd.read_csv(\"temps.csv\", chunksize = 100000)\n\nfor i, temps_df in enumerate(temps_iter): \n    df = prepare_df(temps_df)\n    df.to_sql(\"temperatures\", conn, if_exists=\"replace\" if i == 0 else \"append\", index = False)\nSince the temerature table is ready, we will start to read in the data from the station and country and add them as individual tables into the database.\n# Adding the stations table\nstations = pd.read_csv(\"station-metadata.csv\") \nstations.to_sql(\"stations\", conn, if_exists = \"replace\", index = False)\n\n# Adding the countries table\ncountries = pd.read_csv(\"countries.csv\")\ncountries.to_sql(\"countries\", conn, if_exists = \"replace\", index = False)\nTo make sure that the tables are created, we will use a cursor to look into the SQL table.\ncursor = conn.cursor() \n\ncursor.execute(\"SELECT sql FROM sqlite_master WHERE type='table';\")\n\nfor result in cursor.fetchall():\n    print(result[0])\nYou should get something like this:\n\n\n\nOutput\n\n\nOnce you have this, you have successfully created a climate database."
  },
  {
    "objectID": "posts/HW 1 /index.html#writing-a-query",
    "href": "posts/HW 1 /index.html#writing-a-query",
    "title": "HW 1: Climate Data Visualization",
    "section": "2. Writing a Query",
    "text": "2. Writing a Query\nIn order for us to access the climate-database, we need to write a SQL query. I used the following query to access key information that the homework is asking us to retrieve:\nimport sqlite3\nimport pandas as pd \n\ndef query_climate_database(db_file, country, year_begin, year_end, month): \n    \n    conn = sqlite3.connect(db_file)\n\n    query = f'''\n                SELECT S.name, S.latitude, S.longitude, C.name, T.year, T.month, T.temp\n                FROM temperatures T \n                LEFT JOIN stations S on T.id = S.id\n                LEFT JOIN countries C on SUBSTRING(T.id, 1, 2) = C.'FIPS 10-4'\n                WHERE T.year &gt;= {year_begin} AND T.year &lt;= {year_end} AND T.month == {month} AND C.name == \"{country}\"\n                '''\n\n    df = pd.read_sql_query(query, conn)\n\n    conn.close()\n    return df \nTo keep it short, here is a quick run down about what this query is doing:\nSELECT - Selecting the name, latitude, and longitude from STATIONS; Name from COUNTRIES; Year, Month, and Temp from TEMPERATURES\nFROM - Temperatures table (Aliased as T for readability purposes)  \nLEFT JOIN - IDs from Temperature that equal to the FIPS 10-4 values are to be selected\nLEFT JOIN - Values from Stations that match IDs with values in the Temperatures table\nWHERE - The year is greater than or equal to year_begin and less than or equal to the year_end and where Month equals month and Country equals country.  \nAfter this, you must import the .py file into the index.ipynb file, and you can start making the queries. This is a sample query provided in the homework.\nindia_df = query_climate_database(db_file = \"climate_database.db\",\n                       country = \"India\", \n                       year_begin = 1980, \n                       year_end = 2020,\n                       month = 1)"
  },
  {
    "objectID": "posts/HW 1 /index.html#creating-a-data-visualization",
    "href": "posts/HW 1 /index.html#creating-a-data-visualization",
    "title": "HW 1: Climate Data Visualization",
    "section": "3. Creating a data visualization",
    "text": "3. Creating a data visualization\nFor the assignment, we are required to produce a temperature coefficient plot that reflects an estimate of the yearly change in temperature during the specified month and time period at that station.   As advised, we are going to compute the first coefficient of a linear regression at the station using code from the lecture.   In order to do this, we first must import the necessary packages.\nimport plotly.express as px\nfrom sklearn.linear_model import LinearRegression\nimport datetime\nHere is the temperature_coefficient_plot and coef function provided from the lecture:\ndef coef(data_group):\n    x = data_group[[\"Year\"]] # 2 brackets because X should be a df\n    y = data_group[\"Temp\"]   # 1 bracket because y should be a series\n    LR = LinearRegression()\n    LR.fit(x, y)\n    return LR.coef_[0]\n    \ndef temperature_coefficient_plot(db_file, country, year_begin, year_end, month, min_obs, **kwargs): \n    '''\n    The output of this function should be an interactive geographic scatterplot, \n    constructed using Plotly Express, with a point for each station, such that the \n    color of the point reflects an estimate of the yearly change in temperature during \n    the specified month and time period at that station. \n    A reasonable way to do this is to compute the first coefficient of a linear regression model \n    at that station, as illustrated in the lecture where we used the .apply() method.\n    '''\n    \n    # creating the dataframe\n    df = query_climate_database(db_file, country, year_begin, year_end, month) \n    \n    # Cleaning the dataframe \n    counts = df.groupby([\"NAME\", \"Month\"])[\"Year\"].transform(len)\n    df = df[counts &gt;= min_obs]\n    coefs = df.groupby([\"NAME\", \"Month\", \"LATITUDE\", \"LONGITUDE\"]).apply(coef) #find the estimated yearly change in temperature for each station\n    coefs = coefs.round(3) # round data to 3 decimal places\n    coefs = coefs.reset_index()\n    coefs = coefs.rename(columns = {0 : \"Estimated Yearly Change (C)\"})\n    \n    title = \"Estimates of Yearly Increase in Temperature in {a} for stations in {b}, years {c} - {d}\"\\\n    .format(a=datetime.date(2021, month, 1).strftime('%B'), b=country, c=year_begin, d=year_end)\n    fig = px.scatter_mapbox(coefs,\n                            lat = \"LATITUDE\",\n                            lon = \"LONGITUDE\",\n                            hover_name = \"NAME\",\n                            color = \"Estimated Yearly Change (C)\",\n                            title = title,\n                            **kwargs)\n    return fig\n    \nNow running it, you should see this!"
  },
  {
    "objectID": "posts/HW 1 /index.html#writing-another-query",
    "href": "posts/HW 1 /index.html#writing-another-query",
    "title": "HW 1: Climate Data Visualization",
    "section": "4. Writing Another Query",
    "text": "4. Writing Another Query\nIn order to do this, I am going to write another query in the climate-database.py file. This function will collect the Station name and ID, Country name, and the Temperature year, month, and temperature from the climate-database.\ndef second_climate_database(db_file, country1, country2, year_begin, year_end): \n    \n    conn = sqlite3.connect(db_file) \n    \n    query = f'''\n            SELECT S.ID, S.name, C.name, T.year, T.month, T.temp\n            FROM temperatures T \n            LEFT JOIN stations S on T.id = S.id\n            LEFT JOIN countries C on SUBSTRING(T.id, 1, 2) = C.'FIPS 10-4' \n            \n            WHERE T.year &gt;= {year_begin} AND T.year &lt;= {year_end} AND C.name == \"{country1}\"\n            UNION \n            SELECT S.ID, S.name, C.name, T.year, T.month, T.temp\n            FROM temperatures T \n            LEFT JOIN stations S on T.id = S.id\n            LEFT JOIN countries C on SUBSTRING(T.id, 1, 2) = C.'FIPS 10-4' \n            \n            WHERE T.year &gt;= {year_begin} AND T.year &lt;= {year_end} AND C.name == \"{country2}\"\n            \n            '''\n    \n    df = pd.read_sql_query(query, conn) \n    \n    conn.close() \n    return df \nCreating a data frame of the data, this is what you should expect to get.\ndf = second_climate_database(db_file = \"climate_database.db\", \n                           country1 = \"Philippines\", \n                           country2 = \"Indonesia\",\n                           year_begin = 1970, \n                           year_end = 2020)\ndf\n\nNow onto creating some visualizations from this data set!\n\nComparing the Minimum and Maximum Temperatures from two countries\nIn order to do this, we are going to look at two different countries over the span of 70 years. Using the function call from earlier, we get data from both the Philippines and Indonesia.  \nWe will use the groupby and max() function in order to find both the max and min values per country as follows:\nprint(\"Maximum Temp per Year\")\nmax_data = df.groupby(['Name', 'NAME', 'Year'])['Temp'].max()\nprint(max_data)\n\nprint()\nprint(\"Minimum Temp per Year\")\nmin_data = df.groupby(['Name', 'NAME', 'Year'])['Temp'].min()\nprint(min_data)\n\n# turning them into dataframes \nmin_data_df = min_data.to_frame() \ndisplay(min_data_df)\n\nmax_data_df = max_data.to_frame() \ndisplay(max_data_df)\nThis organizes the data into two seperate dataframes: min_data_df and max_data_df. We will use this in order to calculate the means next.\nprint(\"Min temp mean\")\n# min data \nmin_mean = min_data_df.groupby(['Year', 'Name'])['Temp'].mean()\nprint(min_mean)\n\nprint()\nprint(\"Max temp mean\")\n# max data \nmax_mean = max_data_df.groupby(['Year', 'Name'])['Temp'].mean()\nprint(max_mean)\nNow that this is done, we must convert the datasets into dataframes. Currently, they are series data, therefore we must use the to_frame() and reset_index() in order to do this.\n# converting series to frame \nmin_df = min_mean.to_frame()\nmax_df = max_mean.to_frame()\n\nmin_df = min_df.reset_index()\nmin_df\n\nmax_df = max_df.reset_index() \nmax_df\nNow we can start putting it on a plot! We will create two seperate plots displaying the minimum and maximum temperatures of the countries.\nfig1 = px.line(min_df, x=\"Year\", y=\"Min_Temp\", color=\"Name\", title=\"Comparing the Min Temperatures of the Philippines and Indonesia\")\nfig2 = px.line(max_df, x = \"Year\", y = \"Temp\", color=\"Name\", title=\"Comparing the Max Temperatures of the Philippines and Indonesia\")\n\nfig1.show()\nfig2.show()\n\n\n\nVisualization 2: Comparing the Average Temperatures of Two Different Airports in the Philippines\nSimilar to the first visualization, we first call on the SQL query function for this data.\ndf = second_climate_database(db_file = \"climate_database.db\", \n                           country1 = \"Philippines\", \n                           country2 = \"United States\",\n                           year_begin = 2000, \n                           year_end = 2010)\ndf\nNow, since we are only looking at the Philippines, then we must drop the United States data from the dataframe.\n# filtering the united states data out since we only want to focus on the philippines\ndf_filtered = df[df['Name'] != 'United States']\ndf_filtered\nLet’s look at the unique values in the NAME column to find the airports.\n# now looking at the unique values \nunique_values = df['NAME'].unique()\nunique_values\n\nWe are now going to assign specific airports and start filtering the dataframe so that we only get the values associated with those two airports.\nspecific_airports = ['MANILA_INT_AIRPORT', 'MACTAN_CEBU_INTL'] \n\ndf_filtered = df_filtered[df_filtered['NAME'].isin(specific_airports)]\nprint(df_filtered)\nIn order to compare both, I figured a box plot was most appropriate since this displays the average temperatures for the two airports between 2000 and 2008. Here is what the visualization looks like after running the code:\nfig = px.box(df_filtered, x='Year', y='Temp', color='NAME')\nfig.show()"
  },
  {
    "objectID": "posts/HW 1 /index.html#takeaways",
    "href": "posts/HW 1 /index.html#takeaways",
    "title": "HW 1: Climate Data Visualization",
    "section": "Takeaways",
    "text": "Takeaways\n\nThis assignment was long overdue since I felt very stuck trying to figure out how to do the SQL queries. However, after spending time on them, I slowly started to understand and get the hang of writing them. I thought that it was very helpful to just think about it in a logical way and verbalize them (i.e. I am going to SELECT country names and temperatures FROM the temperature tables WHERE the country names match x.)\n\nI also learned how important data cleaning was! There were many times where my data visualizations did not look correct because I did not clean and organize the dataframes.\n\nThank you for reading on how to create data visualizations!"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/HW4/index.html",
    "href": "posts/HW4/index.html",
    "title": "HW 5: Convolution Layers with Tensor Flow",
    "section": "",
    "text": "Before starting, I had to import all the libraries for this assignment.\n# importing the necessary libraries \nimport os\nfrom keras import utils, datasets, layers, models\nimport keras\nimport tensorflow_datasets as tfds\nimport matplotlib.pyplot as plt\n\n\nWe imported data from a Kaggle dataset that had pictures of cats and dogs. I used the code provided in the homework assignment to do this.\ntrain_ds, validation_ds, test_ds = tfds.load(\n    \"cats_vs_dogs\",\n    # 40% for training, 10% for validation, and 10% for test (the rest unused)\n    split=[\"train[:40%]\", \"train[40%:50%]\", \"train[50%:60%]\"],\n    as_supervised=True,  # Include labels\n)\n\nprint(f\"Number of training samples: {train_ds.cardinality()}\")\nprint(f\"Number of validation samples: {validation_ds.cardinality()}\")\nprint(f\"Number of test samples: {test_ds.cardinality()}\")\nWe also had to resize the images to a fixed size of 150 x 150 since they were not consistent in size. This will allow us to manipulate the NumPy arrays.\n# resizing the images so that they are a fixed size of 150 x 150 \nresize_fn = keras.layers.Resizing(150, 150)\n\ntrain_ds = train_ds.map(lambda x, y: (resize_fn(x), y))\nvalidation_ds = validation_ds.map(lambda x, y: (resize_fn(x), y))\ntest_ds = test_ds.map(lambda x, y: (resize_fn(x), y))\nThis tutorial was largely based off of the Transfer Learning Tutorial via TensorFlow. Some of the code was also taken from there.  \nHere are some snippets of the code that I used from the website:\n# downloading all the necessary data _\n_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\npath_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\nPATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n\ntrain_dir = os.path.join(PATH, 'train')\nvalidation_dir = os.path.join(PATH, 'validation')\n\nBATCH_SIZE = 32\nIMG_SIZE = (160, 160)\n\"\"\"\nCreating the validation and test training datasets. \n\"\"\"\n\ntrain_dataset = tf.keras.utils.image_dataset_from_directory(train_dir,\n                                                            shuffle=True,\n                                                            batch_size=BATCH_SIZE,\n                                                            image_size=IMG_SIZE)\n\nvalidation_dataset = tf.keras.utils.image_dataset_from_directory(validation_dir,\n                                                                 shuffle=True,\n                                                                 batch_size=BATCH_SIZE,\n                                                                 image_size=IMG_SIZE)                              \nThis dataset had photos of both dogs and cats with labels that correspond to each animal. Cats were assigned the value 0, while dogs were assigned the value 1.\n\n\nAfter I imported all the data from the TensorFlow, the homework challenged us to first play around with the dataset. We were tasked to create a plot that has 3 cats in one row and 3 dogs in the second row.  \nTo achieve this, I created a function called two_row(dataset) that takes in a dataset (Here, we would use the test_training sets.). The explanation will be at the bottom.\ndef two_row(dataset):\n\"\"\"\nPurpose: Sorts dogs and cats into distinct rows and outputs a total of 6 images. \n\"\"\"\n\n  plt.figure(figsize=(7, 7)) # initializing the plot \n  \n  # initializing the counters \n  cats_count = 0\n  dogs_count = 0\n\n  for images, labels in dataset.take(1):\n      for i in range(len(images)): \n          if cats_count &lt; 3 and labels[i] == 0: # counts the cats \n              ax = plt.subplot(2, 3, cats_count + 1) \n              plt.imshow(images[i].numpy().astype(\"uint8\"))\n              plt.title(\"Cat\")\n              plt.axis(\"off\")\n              cats_count += 1\n          elif dogs_count &lt; 3 and labels[i] == 1: # counts the dogs \n              ax = plt.subplot(2, 3, 3 + dogs_count + 1)\n              plt.imshow(images[i].numpy().astype(\"uint8\"))\n              plt.title(\"Dog\")\n              plt.axis(\"off\")\n              dogs_count += 1\n          if cats_count == 3 and dogs_count == 3:\n              break  # Exit the loop if both cats and dogs count reach 3\n\n  plt.show()\n\ntwo_row(train_dataset)\n\n\n\nfor images, labels in dataset.take(1) - This goes through both the image and label values and puts them into the condition.\ncats_count and dogs_count - This keeps track of how many dog/cat photos we have.\nif and elif - This is a modification of how the cats and dogs were initially displayed in the 3 x 3 plot, but this time prioritizes putting the same values (cats all in one row) together.\n\nAfter completing this, this is the output: \n\n\n\n\nWe are also interested in how many images of each class our dataset has. I used the iterator provided by the homework to achieve this: labels_iterator= train_ds.unbatch().map(lambda image, label: label).as_numpy_iterator(). I created a for-loop to count how many of each type exists.\nlabels_iterator= train_dataset.unbatch().map(lambda image, label: label).as_numpy_iterator()\n\ndef unique_names(labels_iterator):\n  # initializing the counters\n  dog_count = 0\n  cat_count = 0\n\n  for label in labels_iterator:\n    if label == 0:\n      cat_count += 1\n\n    elif label == 1:\n      dog_count += 1\n\n  print(\"Number of cat images: \", cat_count)\n  print(\"Number of dog images: \", dog_count)\n\nunique_names(labels_iterator)\n\n\n\n\n\n\n\nNext, we are tasked to create a keras.Sequential model using the layers that I learned from class.\nThis is the model that I wrote which has all of the necessary requirements:\n# building the sequential model\n\nmodel1 = models.Sequential([\n    layers.InputLayer(input_shape=(160,160,3)), # initial input\n\n    # Hidden layers\n    layers.Conv2D(16, (3,3), activation='relu'),\n    layers.MaxPooling2D((2,2)),\n    layers.Conv2D(16, (3,3), activation='relu'),\n    layers.MaxPooling2D((2,2)),\n    layers.Conv2D(32, (3,3), activation='relu'),\n    layers.MaxPooling2D((2,2)),\n\n    # Output\n    layers.Flatten(),\n    layers.Dense(64, activation='relu'),\n    layers.Dropout(0.3),\n    layers.Dense(5)\n])\n\n\n\nConv2D -\nMaxPooling2D -\nFlatten() -\nDense(64, activation='relu') -\nDense(5) -\n\nNow, lets check the summary of our model.\nmodel1.summary()\nModel: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d (Conv2D)             (None, 158, 158, 16)      448       \n                                                                 \n max_pooling2d (MaxPooling2  (None, 79, 79, 16)        0         \n D)                                                              \n                                                                 \n conv2d_1 (Conv2D)           (None, 77, 77, 16)        2320      \n                                                                 \n max_pooling2d_1 (MaxPoolin  (None, 38, 38, 16)        0         \n g2D)                                                            \n                                                                 \n conv2d_2 (Conv2D)           (None, 36, 36, 32)        4640      \n                                                                 \n max_pooling2d_2 (MaxPoolin  (None, 18, 18, 32)        0         \n g2D)                                                            \n                                                                 \n flatten (Flatten)           (None, 10368)             0         \n                                                                 \n dense (Dense)               (None, 64)                663616    \n                                                                 \n dropout (Dropout)           (None, 64)                0         \n                                                                 \n dense_1 (Dense)             (None, 5)                 325       \n                                                                 \n=================================================================\nTotal params: 671349 (2.56 MB)\nTrainable params: 671349 (2.56 MB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________"
  },
  {
    "objectID": "posts/HW4/index.html#access-the-data",
    "href": "posts/HW4/index.html#access-the-data",
    "title": "HW 5: Convolution Layers with Tensor Flow",
    "section": "",
    "text": "We imported data from a Kaggle dataset that had pictures of cats and dogs. I used the code provided in the homework assignment to do this.\ntrain_ds, validation_ds, test_ds = tfds.load(\n    \"cats_vs_dogs\",\n    # 40% for training, 10% for validation, and 10% for test (the rest unused)\n    split=[\"train[:40%]\", \"train[40%:50%]\", \"train[50%:60%]\"],\n    as_supervised=True,  # Include labels\n)\n\nprint(f\"Number of training samples: {train_ds.cardinality()}\")\nprint(f\"Number of validation samples: {validation_ds.cardinality()}\")\nprint(f\"Number of test samples: {test_ds.cardinality()}\")\nWe also had to resize the images to a fixed size of 150 x 150 since they were not consistent in size. This will allow us to manipulate the NumPy arrays.\n# resizing the images so that they are a fixed size of 150 x 150 \nresize_fn = keras.layers.Resizing(150, 150)\n\ntrain_ds = train_ds.map(lambda x, y: (resize_fn(x), y))\nvalidation_ds = validation_ds.map(lambda x, y: (resize_fn(x), y))\ntest_ds = test_ds.map(lambda x, y: (resize_fn(x), y))\nThis tutorial was largely based off of the Transfer Learning Tutorial via TensorFlow. Some of the code was also taken from there.  \nHere are some snippets of the code that I used from the website:\n# downloading all the necessary data _\n_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\npath_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\nPATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n\ntrain_dir = os.path.join(PATH, 'train')\nvalidation_dir = os.path.join(PATH, 'validation')\n\nBATCH_SIZE = 32\nIMG_SIZE = (160, 160)\n\"\"\"\nCreating the validation and test training datasets. \n\"\"\"\n\ntrain_dataset = tf.keras.utils.image_dataset_from_directory(train_dir,\n                                                            shuffle=True,\n                                                            batch_size=BATCH_SIZE,\n                                                            image_size=IMG_SIZE)\n\nvalidation_dataset = tf.keras.utils.image_dataset_from_directory(validation_dir,\n                                                                 shuffle=True,\n                                                                 batch_size=BATCH_SIZE,\n                                                                 image_size=IMG_SIZE)                              \nThis dataset had photos of both dogs and cats with labels that correspond to each animal. Cats were assigned the value 0, while dogs were assigned the value 1.\n\n\nAfter I imported all the data from the TensorFlow, the homework challenged us to first play around with the dataset. We were tasked to create a plot that has 3 cats in one row and 3 dogs in the second row.  \nTo achieve this, I created a function called two_row(dataset) that takes in a dataset (Here, we would use the test_training sets.). The explanation will be at the bottom.\ndef two_row(dataset):\n\"\"\"\nPurpose: Sorts dogs and cats into distinct rows and outputs a total of 6 images. \n\"\"\"\n\n  plt.figure(figsize=(7, 7)) # initializing the plot \n  \n  # initializing the counters \n  cats_count = 0\n  dogs_count = 0\n\n  for images, labels in dataset.take(1):\n      for i in range(len(images)): \n          if cats_count &lt; 3 and labels[i] == 0: # counts the cats \n              ax = plt.subplot(2, 3, cats_count + 1) \n              plt.imshow(images[i].numpy().astype(\"uint8\"))\n              plt.title(\"Cat\")\n              plt.axis(\"off\")\n              cats_count += 1\n          elif dogs_count &lt; 3 and labels[i] == 1: # counts the dogs \n              ax = plt.subplot(2, 3, 3 + dogs_count + 1)\n              plt.imshow(images[i].numpy().astype(\"uint8\"))\n              plt.title(\"Dog\")\n              plt.axis(\"off\")\n              dogs_count += 1\n          if cats_count == 3 and dogs_count == 3:\n              break  # Exit the loop if both cats and dogs count reach 3\n\n  plt.show()\n\ntwo_row(train_dataset)\n\n\n\nfor images, labels in dataset.take(1) - This goes through both the image and label values and puts them into the condition.\ncats_count and dogs_count - This keeps track of how many dog/cat photos we have.\nif and elif - This is a modification of how the cats and dogs were initially displayed in the 3 x 3 plot, but this time prioritizes putting the same values (cats all in one row) together.\n\nAfter completing this, this is the output: \n\n\n\n\nWe are also interested in how many images of each class our dataset has. I used the iterator provided by the homework to achieve this: labels_iterator= train_ds.unbatch().map(lambda image, label: label).as_numpy_iterator(). I created a for-loop to count how many of each type exists.\nlabels_iterator= train_dataset.unbatch().map(lambda image, label: label).as_numpy_iterator()\n\ndef unique_names(labels_iterator):\n  # initializing the counters\n  dog_count = 0\n  cat_count = 0\n\n  for label in labels_iterator:\n    if label == 0:\n      cat_count += 1\n\n    elif label == 1:\n      dog_count += 1\n\n  print(\"Number of cat images: \", cat_count)\n  print(\"Number of dog images: \", dog_count)\n\nunique_names(labels_iterator)"
  },
  {
    "objectID": "posts/HW4/index.html#first-model",
    "href": "posts/HW4/index.html#first-model",
    "title": "HW 5: Convolution Layers with Tensor Flow",
    "section": "",
    "text": "Next, we are tasked to create a keras.Sequential model using the layers that I learned from class.\nThis is the model that I wrote which has all of the necessary requirements:\n# building the sequential model\n\nmodel1 = models.Sequential([\n    layers.InputLayer(input_shape=(160,160,3)), # initial input\n\n    # Hidden layers\n    layers.Conv2D(16, (3,3), activation='relu'),\n    layers.MaxPooling2D((2,2)),\n    layers.Conv2D(16, (3,3), activation='relu'),\n    layers.MaxPooling2D((2,2)),\n    layers.Conv2D(32, (3,3), activation='relu'),\n    layers.MaxPooling2D((2,2)),\n\n    # Output\n    layers.Flatten(),\n    layers.Dense(64, activation='relu'),\n    layers.Dropout(0.3),\n    layers.Dense(5)\n])\n\n\n\nConv2D -\nMaxPooling2D -\nFlatten() -\nDense(64, activation='relu') -\nDense(5) -\n\nNow, lets check the summary of our model.\nmodel1.summary()\nModel: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d (Conv2D)             (None, 158, 158, 16)      448       \n                                                                 \n max_pooling2d (MaxPooling2  (None, 79, 79, 16)        0         \n D)                                                              \n                                                                 \n conv2d_1 (Conv2D)           (None, 77, 77, 16)        2320      \n                                                                 \n max_pooling2d_1 (MaxPoolin  (None, 38, 38, 16)        0         \n g2D)                                                            \n                                                                 \n conv2d_2 (Conv2D)           (None, 36, 36, 32)        4640      \n                                                                 \n max_pooling2d_2 (MaxPoolin  (None, 18, 18, 32)        0         \n g2D)                                                            \n                                                                 \n flatten (Flatten)           (None, 10368)             0         \n                                                                 \n dense (Dense)               (None, 64)                663616    \n                                                                 \n dropout (Dropout)           (None, 64)                0         \n                                                                 \n dense_1 (Dense)             (None, 5)                 325       \n                                                                 \n=================================================================\nTotal params: 671349 (2.56 MB)\nTrainable params: 671349 (2.56 MB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  },
  {
    "objectID": "posts/Palmer Penguins/index.html",
    "href": "posts/Palmer Penguins/index.html",
    "title": "HW0: Palmer Penguins",
    "section": "",
    "text": "🛑 BEFORE STARTING 🛑 Make sure to import these libraries used: Plotly, Pandas, Numpy, Seaborn\n\n\nimport pandas as pd\nurl = \"https://raw.githubusercontent.com/pic16b-ucla/24W/main/datasets/palmer_penguins.csv\"\npenguins = pd.read_csv(url)\n\n\n\npenguins.info()\n\n# cleaning the data\npenguins.isnull().sum()\n\n# filling nan values with 0\npenguins.fillna(0)\n\n\n\n.info()\n\nPresents the information of each column and the amount of entries within each column.\n\n.isnull().sum()\n\nTakes the sum of each column that has a NaN value.\n\n\n\n\n\n\n“Plotly’s Python graphing library makes interactive, publication-quality graphs. Examples of how to make line plots, scatter plots, area charts, bar charts, error bars, box plots, histograms, heatmaps, subplots, multiple-axes, polar charts, and bubble charts.” – From Plotly Website\n☃️ I decided to use plotly because of its ability to create complex but informational graphs, charts, plots easily. I utilized the scatterplot code from their documentation to create the plot.\nfrom plotly import express as px\n\n# create a scatter plot\nfig = px.scatter(data_frame = penguins, x = 'Body Mass (g)', y = 'Flipper Length (mm)', color = \"Species\",\n                 width = 1000, height = 600, title = \"Flipper Length (mm) and Body Mass (g) for Penguin Species\")\n\nfig.update_layout(margin={\"r\":0, \"t\":50, \"l\":0, \"b\":0})\n\n#show the plot\nfig.show()\n☃️ I chose to represent the flipper length (mm) and body mass (g) for all penguin species that were present in the data set.\n\n\n\nAs a result, I got this table!\n\n\n\nThis is the plot I made!\n\n\n\n\n\n⭐️ It was a good introduction to writing Quarto blogs. It took me a while to understand, but I managed to do it so I think that is what mattered the most. :&gt;\n⭐️ I want to work towards learning to read and search through documentation. In order to create the plots, I had to outsource to the Plotly documentation website, which required some reading and attention."
  },
  {
    "objectID": "posts/Palmer Penguins/index.html#task-write-a-tutorial-explaining-how-to-construct-an-interesting-data-visualization-of-the-palmer-penguins-data-set.",
    "href": "posts/Palmer Penguins/index.html#task-write-a-tutorial-explaining-how-to-construct-an-interesting-data-visualization-of-the-palmer-penguins-data-set.",
    "title": "HW0: Palmer Penguins",
    "section": "",
    "text": "🛑 BEFORE STARTING 🛑 Make sure to import these libraries used: Plotly, Pandas, Numpy, Seaborn\n\n\nimport pandas as pd\nurl = \"https://raw.githubusercontent.com/pic16b-ucla/24W/main/datasets/palmer_penguins.csv\"\npenguins = pd.read_csv(url)\n\n\n\npenguins.info()\n\n# cleaning the data\npenguins.isnull().sum()\n\n# filling nan values with 0\npenguins.fillna(0)\n\n\n\n.info()\n\nPresents the information of each column and the amount of entries within each column.\n\n.isnull().sum()\n\nTakes the sum of each column that has a NaN value.\n\n\n\n\n\n\n“Plotly’s Python graphing library makes interactive, publication-quality graphs. Examples of how to make line plots, scatter plots, area charts, bar charts, error bars, box plots, histograms, heatmaps, subplots, multiple-axes, polar charts, and bubble charts.” – From Plotly Website\n☃️ I decided to use plotly because of its ability to create complex but informational graphs, charts, plots easily. I utilized the scatterplot code from their documentation to create the plot.\nfrom plotly import express as px\n\n# create a scatter plot\nfig = px.scatter(data_frame = penguins, x = 'Body Mass (g)', y = 'Flipper Length (mm)', color = \"Species\",\n                 width = 1000, height = 600, title = \"Flipper Length (mm) and Body Mass (g) for Penguin Species\")\n\nfig.update_layout(margin={\"r\":0, \"t\":50, \"l\":0, \"b\":0})\n\n#show the plot\nfig.show()\n☃️ I chose to represent the flipper length (mm) and body mass (g) for all penguin species that were present in the data set.\n\n\n\nAs a result, I got this table!\n\n\n\nThis is the plot I made!\n\n\n\n\n\n⭐️ It was a good introduction to writing Quarto blogs. It took me a while to understand, but I managed to do it so I think that is what mattered the most. :&gt;\n⭐️ I want to work towards learning to read and search through documentation. In order to create the plots, I had to outsource to the Plotly documentation website, which required some reading and attention."
  },
  {
    "objectID": "posts/HW3/index.html",
    "href": "posts/HW3/index.html",
    "title": "HW 3: Flask App Development",
    "section": "",
    "text": "Before starting, I had to import the following libraries in order to complete this assignment:\n\nfrom flask import Flask, g, render_template, request\nimport sqlite3\n\nNext, create and launch the Flask app using this.\n\napp = Flask(__name__)\n\nHere is the GitHub Repository for this: GitHub  \nNow you are ready to start building your website!\n\n\nAs per the instructions, we are asked to create a submit template with three user inteface elements:\n\nA text box for submitting a message.\nA textbox for submitting the name of the user.\nA “submit” button.\n\nI wrote the following code in the submit.html file first and I will explain as follows:\n{% extends 'base.html' %}\n\n{% block header %}\n&lt;h1&gt;{% block title %}Submit a Message{% endblock %}&lt;/h1&gt;\n{% endblock %}\n\n{% block content %}\n&lt;form method=\"post\"&gt;\n    &lt;label for=\"message\"&gt;Your message:&lt;/label&gt;\n    &lt;br&gt;\n    &lt;input type=\"text\" name=\"message\" id=\"message\"&gt;\n    &lt;br&gt;\n    &lt;label for=\"name\"&gt;Your name or handle:&lt;/label&gt;\n    &lt;br&gt;\n    &lt;input type=\"text\" name=\"name\" id=\"name\"&gt;\n    &lt;br&gt;\n    &lt;input type=\"submit\" value=\"Submit message\"&gt;\n&lt;/form&gt;\n\n{% if (name) and (message) %}\n&lt;br&gt;\n&lt;b&gt;Hello {{name}}, Thank you for submitting your message! &lt;/b&gt;\n{% else %}\n&lt;b&gt; Please submit all entries &lt;/b&gt;\n{% endif %}\n{% endblock %}\n\n\n\n{% extends 'base.html' %} - This allows for an extension from the ‘base.html’ file and replaces the templates with the content on this page but still maintaining the navigation bar on top.\n&lt;form method=\"post\"&gt; Section - This block of content contains the necessary code in order to meet the submission requirements.\n\nThe message allows for a text input from the user which creates a box. This is the same idea for the getting the name.\n‘Submit message’ - This is the submission button.\n\nThe rest of the code simply outputs a message that thanks the user {name} for their input.\n\nBefore adding this to the app.py, we must build a SQL database and insertion function to store the messages.\n\n\n\nThe purpose of this function allows for the creation of the message database.   In order to build this, we must first check if the message table exists within the message_db.sqlite. We check this by writing a SQL query as so:\n    cursor.execute(\"CREATE TABLE IF NOT EXISTS messages (handle TEXT, message TEXT);\")\nWe check if there is a database called message_db in the g attribute of the app. Then once there is confirmation, then we do not need to connect one. If there is, then that is when we are going to connect a new database.\nI wrote the following code to demonstrate this (which also includes the query):\ndef get_message_db():\n    # purpose: to handle a database full of messages \n    if 'db' not in g: \n       g.message_db = sqlite3.connect('message_db.sqlite')\n\n    conn = g.message_db\n    cursor = conn.cursor()\n\n    # creating the table if it does not exist \n    cursor.execute(\"CREATE TABLE IF NOT EXISTS messages (handle TEXT, message TEXT);\")\n\n    return g.message_db\nNow you are done writing the get_message_db() function.\n\n\n\nThis function handles inserting a user message into the database.\nRecall that we specified the message and handle objects in the submit.html file. We are going to retrieve those with the request function. We are going to access them with the request.form[\"message/name\"] method.\nThis is how I built this function:\ndef insert_message(request):\n  # extracting the message and handle from the request \n  message = request.form[\"message\"]\n  handle = request.form[\"name\"]\n\n  db = get_message_db() \n  error = None # keeping track of empty messages \n\n  if error is None: \n     db.execute(\"INSERT INTO messages (handle, message) VALUES (?,?)\", (handle, message)) # query to add the messages to the db \n     db.commit() \n\n  db.close() \n\n  return message, handle\nFinally, we are ready to build the submit app route.\n\n\n\n\nNext, we are going to interact with the submit function on the app.py.\nIn the app.py, this houses all the url routes to different pages in your website.   I wrote the following code in order to do this.\n@app.route('/send-message/', methods=['POST', 'GET'])\ndef send_message(): \n   if request.method == 'GET': \n    return render_template('submit.html')\n   \n   else:\n      try: \n        insert_message(request) # running insert message \n        return render_template('submit.html', name=request.form['name'], message=request.form['message']) # returns submit html with the successful submission\n      except: \n         return render_template('submit.html') \n\n\n\n@app.route('/send-messge/') - This produces the URL extension so that we can access the submission page.\nsend_message() - This function handles the SQL database that stores the messages.\ninsert_message(request) - This calls the function that inserts the message into the SQL database.\nrender_template('submit.html') - This calls the template to be shown on the screen when this URL/page is being accesssed. Here, it will show what we wrote for the submissions category.\n\nIf you run the website, this is what it looks like!\n\n\n\nCompleted submission area\n\n\n\n\n\n\nWe are tasked to build a way to view the messages on the navigation.\nBefore we start, we first make View a Random Message an option on the navigation bar.\n&lt;li&gt;&lt;a href=\"{{ url_for('view') }}\"&gt;View a Random Message&lt;/a&gt;&lt;/li&gt;\n\n\n\nNavigation Bar\n\n\nThen, we are going to make a function random_messages(n) that helps show the submissions (name and handle) to the user.\n\nThis communicates with the get_message_db function, meaning that it communicates with the SQL database that we created earlier.\n\ndef random_messages(n): \n   \"\"\"\n   Returns random messages\n   \"\"\"\n\n   db = get_message_db() \n   cursor = db.cursor() \n  \n   cursor.execute(\"SELECT message, handle FROM messages ORDER BY RANDOM() LIMIT (?)\", (n,))\n   messages = cursor.fetchall()\n\n   db.close() \n\n   return messages \n\n\n\nSQL query cursor.execute(\"SELECT message, handle FROM messages ORDER BY RANDOM() LIMIT (?)\", (n,)) - This selects the message and handle value from the table messages in a random order and only takes 5 of them at a single time.\n\nNow, we are going to create a view.html file that creates another page to view the messages.\nSimilar to the submit.html file, this will create extend the base.html we made so that the navigation bar still exists.\n{% extends 'base.html' %}\n\n{% block header %}\n&lt;h1&gt;{% block title %}View some epic messages!{% endblock %}&lt;/h1&gt;\n{% endblock %}\n\n{% block content %}\n  {% for content in message_list %}\n  &lt;br&gt;\n  &lt;b&gt;{{content.0}}&lt;/b&gt;\n  &lt;br&gt;\n  &lt;i&gt;{{content.1}}&lt;/i&gt;\n  &lt;br&gt;\n  {% endfor %}\n{% endblock %}\n\n\n\n\nThe {% for content in message_list %} loop will go through the messages, then select and display them randomly on the screen.\n\nAfter we created this, we will go back to the app.py so that we can build a URL route to access this page.\n@app.route('/view/')\ndef view(): \n  limit = 5\n  mylist=random_messages(limit) # runs the random amt of messages\n  return render_template('view.html', message_list = mylist)\n\n\n\n\nlimit = 5 - This limits the amount of messages that the function will output to 5.\nSimilar process to the previous routes, it will call the function and render the template that we created.\n\nAfter that is complete, this is what your website should look like:\n\n\n\nView Messages\n\n\nAnd that’s it for the tutorial! Congratulations, you have a complete website!\n\n\n\n\n\nOne of the things that was most challenging was understanding how the app.routes and the templates connected to one another. I kept running into Internal server errors all the time when trying to connect them. After reading a few tutorials, I managed to do them.\nWeb dev is fun! I really like playing around with the design and learning the back end work was super neat! :D"
  },
  {
    "objectID": "posts/HW3/index.html#enable-submissions",
    "href": "posts/HW3/index.html#enable-submissions",
    "title": "HW 3: Flask App Development",
    "section": "",
    "text": "As per the instructions, we are asked to create a submit template with three user inteface elements:\n\nA text box for submitting a message.\nA textbox for submitting the name of the user.\nA “submit” button.\n\nI wrote the following code in the submit.html file first and I will explain as follows:\n{% extends 'base.html' %}\n\n{% block header %}\n&lt;h1&gt;{% block title %}Submit a Message{% endblock %}&lt;/h1&gt;\n{% endblock %}\n\n{% block content %}\n&lt;form method=\"post\"&gt;\n    &lt;label for=\"message\"&gt;Your message:&lt;/label&gt;\n    &lt;br&gt;\n    &lt;input type=\"text\" name=\"message\" id=\"message\"&gt;\n    &lt;br&gt;\n    &lt;label for=\"name\"&gt;Your name or handle:&lt;/label&gt;\n    &lt;br&gt;\n    &lt;input type=\"text\" name=\"name\" id=\"name\"&gt;\n    &lt;br&gt;\n    &lt;input type=\"submit\" value=\"Submit message\"&gt;\n&lt;/form&gt;\n\n{% if (name) and (message) %}\n&lt;br&gt;\n&lt;b&gt;Hello {{name}}, Thank you for submitting your message! &lt;/b&gt;\n{% else %}\n&lt;b&gt; Please submit all entries &lt;/b&gt;\n{% endif %}\n{% endblock %}\n\n\n\n{% extends 'base.html' %} - This allows for an extension from the ‘base.html’ file and replaces the templates with the content on this page but still maintaining the navigation bar on top.\n&lt;form method=\"post\"&gt; Section - This block of content contains the necessary code in order to meet the submission requirements.\n\nThe message allows for a text input from the user which creates a box. This is the same idea for the getting the name.\n‘Submit message’ - This is the submission button.\n\nThe rest of the code simply outputs a message that thanks the user {name} for their input.\n\nBefore adding this to the app.py, we must build a SQL database and insertion function to store the messages.\n\n\n\nThe purpose of this function allows for the creation of the message database.   In order to build this, we must first check if the message table exists within the message_db.sqlite. We check this by writing a SQL query as so:\n    cursor.execute(\"CREATE TABLE IF NOT EXISTS messages (handle TEXT, message TEXT);\")\nWe check if there is a database called message_db in the g attribute of the app. Then once there is confirmation, then we do not need to connect one. If there is, then that is when we are going to connect a new database.\nI wrote the following code to demonstrate this (which also includes the query):\ndef get_message_db():\n    # purpose: to handle a database full of messages \n    if 'db' not in g: \n       g.message_db = sqlite3.connect('message_db.sqlite')\n\n    conn = g.message_db\n    cursor = conn.cursor()\n\n    # creating the table if it does not exist \n    cursor.execute(\"CREATE TABLE IF NOT EXISTS messages (handle TEXT, message TEXT);\")\n\n    return g.message_db\nNow you are done writing the get_message_db() function.\n\n\n\nThis function handles inserting a user message into the database.\nRecall that we specified the message and handle objects in the submit.html file. We are going to retrieve those with the request function. We are going to access them with the request.form[\"message/name\"] method.\nThis is how I built this function:\ndef insert_message(request):\n  # extracting the message and handle from the request \n  message = request.form[\"message\"]\n  handle = request.form[\"name\"]\n\n  db = get_message_db() \n  error = None # keeping track of empty messages \n\n  if error is None: \n     db.execute(\"INSERT INTO messages (handle, message) VALUES (?,?)\", (handle, message)) # query to add the messages to the db \n     db.commit() \n\n  db.close() \n\n  return message, handle\nFinally, we are ready to build the submit app route."
  },
  {
    "objectID": "posts/HW3/index.html#create-the-submit-app-route-on-app.py.",
    "href": "posts/HW3/index.html#create-the-submit-app-route-on-app.py.",
    "title": "HW 3: Flask App Development",
    "section": "",
    "text": "Next, we are going to interact with the submit function on the app.py.\nIn the app.py, this houses all the url routes to different pages in your website.   I wrote the following code in order to do this.\n@app.route('/send-message/', methods=['POST', 'GET'])\ndef send_message(): \n   if request.method == 'GET': \n    return render_template('submit.html')\n   \n   else:\n      try: \n        insert_message(request) # running insert message \n        return render_template('submit.html', name=request.form['name'], message=request.form['message']) # returns submit html with the successful submission\n      except: \n         return render_template('submit.html') \n\n\n\n@app.route('/send-messge/') - This produces the URL extension so that we can access the submission page.\nsend_message() - This function handles the SQL database that stores the messages.\ninsert_message(request) - This calls the function that inserts the message into the SQL database.\nrender_template('submit.html') - This calls the template to be shown on the screen when this URL/page is being accesssed. Here, it will show what we wrote for the submissions category.\n\nIf you run the website, this is what it looks like!\n\n\n\nCompleted submission area"
  },
  {
    "objectID": "posts/HW3/index.html#view-a-random-message",
    "href": "posts/HW3/index.html#view-a-random-message",
    "title": "HW 3: Flask App Development",
    "section": "",
    "text": "We are tasked to build a way to view the messages on the navigation.\nBefore we start, we first make View a Random Message an option on the navigation bar.\n&lt;li&gt;&lt;a href=\"{{ url_for('view') }}\"&gt;View a Random Message&lt;/a&gt;&lt;/li&gt;\n\n\n\nNavigation Bar\n\n\nThen, we are going to make a function random_messages(n) that helps show the submissions (name and handle) to the user.\n\nThis communicates with the get_message_db function, meaning that it communicates with the SQL database that we created earlier.\n\ndef random_messages(n): \n   \"\"\"\n   Returns random messages\n   \"\"\"\n\n   db = get_message_db() \n   cursor = db.cursor() \n  \n   cursor.execute(\"SELECT message, handle FROM messages ORDER BY RANDOM() LIMIT (?)\", (n,))\n   messages = cursor.fetchall()\n\n   db.close() \n\n   return messages \n\n\n\nSQL query cursor.execute(\"SELECT message, handle FROM messages ORDER BY RANDOM() LIMIT (?)\", (n,)) - This selects the message and handle value from the table messages in a random order and only takes 5 of them at a single time.\n\nNow, we are going to create a view.html file that creates another page to view the messages.\nSimilar to the submit.html file, this will create extend the base.html we made so that the navigation bar still exists.\n{% extends 'base.html' %}\n\n{% block header %}\n&lt;h1&gt;{% block title %}View some epic messages!{% endblock %}&lt;/h1&gt;\n{% endblock %}\n\n{% block content %}\n  {% for content in message_list %}\n  &lt;br&gt;\n  &lt;b&gt;{{content.0}}&lt;/b&gt;\n  &lt;br&gt;\n  &lt;i&gt;{{content.1}}&lt;/i&gt;\n  &lt;br&gt;\n  {% endfor %}\n{% endblock %}\n\n\n\n\nThe {% for content in message_list %} loop will go through the messages, then select and display them randomly on the screen.\n\nAfter we created this, we will go back to the app.py so that we can build a URL route to access this page.\n@app.route('/view/')\ndef view(): \n  limit = 5\n  mylist=random_messages(limit) # runs the random amt of messages\n  return render_template('view.html', message_list = mylist)\n\n\n\n\nlimit = 5 - This limits the amount of messages that the function will output to 5.\nSimilar process to the previous routes, it will call the function and render the template that we created.\n\nAfter that is complete, this is what your website should look like:\n\n\n\nView Messages\n\n\nAnd that’s it for the tutorial! Congratulations, you have a complete website!"
  },
  {
    "objectID": "posts/HW3/index.html#takeaways",
    "href": "posts/HW3/index.html#takeaways",
    "title": "HW 3: Flask App Development",
    "section": "",
    "text": "One of the things that was most challenging was understanding how the app.routes and the templates connected to one another. I kept running into Internal server errors all the time when trying to connect them. After reading a few tutorials, I managed to do them.\nWeb dev is fun! I really like playing around with the design and learning the back end work was super neat! :D"
  },
  {
    "objectID": "posts/PROJECT/index.html",
    "href": "posts/PROJECT/index.html",
    "title": "User Vs. The World",
    "section": "",
    "text": "For the final project, we built a data visualization that takes in data from the user and compares them to countries. They will be matched with a country that has similar music tastes with the user.\nTeam members: Justine Constantino, Andrew Han, Jessica Xiao\nLink to Github Repository"
  },
  {
    "objectID": "posts/PROJECT/index.html#purpose-of-user-vs.-the-world",
    "href": "posts/PROJECT/index.html#purpose-of-user-vs.-the-world",
    "title": "User Vs. The World",
    "section": "Purpose of User Vs. The World",
    "text": "Purpose of User Vs. The World\nUser Vs. The World is meant to connect different users to countries and learn more about them through music. Our app aims to help users discover new cultures through similar music tastes that countries have.\n\nTarget Audience\nWe aim to target those who are interested in seeking out songs from different countries that they may have similar interests with.\n\n\nHow We Built the App\nIn order to build our web app, we scraped data from kworbs.net, implemented a SQL database, and created data visualizations via Plotly Dash website.\n\nPlotly Dash: Plotly Dash is a Python interface that creates interactive web applications. We used this to help integrate plotly to create a dynamic dashboard.\nPlotly: Plotly is a python library that helps build complex, dynamic, and interactive data visualizations. We used Plotly to help create our graphs."
  },
  {
    "objectID": "posts/PROJECT/index.html#technical-components",
    "href": "posts/PROJECT/index.html#technical-components",
    "title": "User Vs. The World",
    "section": "Technical Components",
    "text": "Technical Components\n\nWeb scraping and Datacleaning:\n\nThe first step that we had to do was to scrape data. We utilized BeautifulSoup, which is a Python package that parses HTML and XML documents. We scraped from kworbs.net, specifically from their Spotify Charts data. We scraped 200 songs from a total of 75 countries. The songs come from weekly charts and go from a rank of 1-200. After scraping the data, we imported it onto a CSV file and cleaned it up so that the columns contained: rank, song_title, artist_name, which are the important pieces of content that we need for the project.\n\n\n \n\nSQL Database\n\nWe inserted all the data into a SQL database for easier access when trying to compare the country data to the user data. We created four tables: songs, countries, country_data, rank_data. For this project, we mainly used the countries table since it was the most straightforward. We created different queries depending on what we needed, such as selecting unique songs per country.\nHere is an example of the tables within the database. \n\nWeb Development with Plotly Dash\n\nDash’s interface allowed graphs to be plotted easily on a web app. We had to learn how to code in Dash using their documentation and this is our final result."
  },
  {
    "objectID": "posts/PROJECT/index.html#final-web-app",
    "href": "posts/PROJECT/index.html#final-web-app",
    "title": "User Vs. The World",
    "section": "Final Web App",
    "text": "Final Web App\n\nComponents of Our Website\n\nDropdown Bar\n\nThe dropdown bar gives options of what graph the user wants to select: Top 15 Artists, Top 50 Songs, Countries that the users matched to.\n\nGraphs\n\nThe graphs change depending on what the option the user decides to choose. The options are listed above. Here are some examples of the graphs:\n\nRecommendation System: We built the recommendation system by using a SQL query that accesses the database, and looks through each otf the countries and retrieves distinct songs specific to that country. The user’s top tracks will be retrieved and then see which songs from each country match with them. Whichever country has the most songs matching with the user, then that is the country they match most.\n\nHere is an example of what the website looks like:\n\n\n\nHomepage\n\n\n\n\n\nDrop Down\n\n\n\n\n\nTop Artist Data"
  },
  {
    "objectID": "posts/PROJECT/index.html#takeaways",
    "href": "posts/PROJECT/index.html#takeaways",
    "title": "User Vs. The World",
    "section": "Takeaways",
    "text": "Takeaways\n\nI learned many things from this project. I feel like we were quite ambitious with what we wanted to deliver, which led us to not completing a lot of our project. It felt overwhelming to balance all the elements, components, along with the time that my groupmates could dedicate to this project. However, I am content with the fact that we were able to produce something that worked and catered to our original goals. We understand that there are a lot of different things that we can improve upon, however we were able to meet the specifications for the project which is the best part."
  },
  {
    "objectID": "posts/PROJECT/index.html#ways-to-improve",
    "href": "posts/PROJECT/index.html#ways-to-improve",
    "title": "User Vs. The World",
    "section": "Ways to Improve",
    "text": "Ways to Improve\n\nAesthetics: There are many ways to improve upon our project, and I believe the biggest one is the aesthetics. It could be improved more upon the way the layouts and the color, but this comes with knowing how code more in Dash.\nRecommendations System: We noticed that there were only a few common songs shared between the country and the user. Perhaps the recommendation system can be changed so that there is another way to figure out the similarities between the user and their respective country."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Winter PIC16A",
    "section": "",
    "text": "HW 2: Movie Database Scraper\n\n\n\n\n\n\nweek 2\n\n\nHomework 2\n\n\n\n\n\n\n\n\n\nOct 1, 2025\n\n\nJustine Constantino\n\n\n\n\n\n\n\n\n\n\n\n\nHW0: Palmer Penguins\n\n\n\n\n\n\nweek 1\n\n\nHomework 0\n\n\n\n\n\n\n\n\n\nOct 1, 2025\n\n\nJustine Constantino\n\n\n\n\n\n\n\n\n\n\n\n\nUser Vs. The World\n\n\n\n\n\n\nweek 10\n\n\nProject\n\n\n\n\n\n\n\n\n\nMar 23, 2024\n\n\nJustine Constantino\n\n\n\n\n\n\n\n\n\n\n\n\nHW 5: Convolution Layers with Tensor Flow\n\n\n\n\n\n\nweek 5\n\n\nHomework 5\n\n\n\n\n\n\n\n\n\nMar 18, 2024\n\n\nJustine Constantino\n\n\n\n\n\n\n\n\n\n\n\n\nHW 3: Flask App Development\n\n\n\n\n\n\nweek 3\n\n\nHomework 3\n\n\n\n\n\n\n\n\n\nMar 17, 2024\n\n\nJustine Constantino\n\n\n\n\n\n\n\n\n\n\n\n\nHW 1: Climate Data Visualization\n\n\n\n\n\n\nweek 1\n\n\nHomework 1\n\n\n\n\n\n\n\n\n\nMar 11, 2024\n\n\nJustine Constantino\n\n\n\n\n\n\n\n\n\n\n\n\nPost With Code\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nJan 11, 2024\n\n\nHarlow Malloc\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nJan 8, 2024\n\n\nTristan O’Malley\n\n\n\n\n\n\nNo matching items"
  }
]